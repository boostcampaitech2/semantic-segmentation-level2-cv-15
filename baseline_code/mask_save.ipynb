{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install curl -y\n",
    "# !curl 'https://bootstrap.pypa.io/get-pip.py' -o get-pip.py\n",
    "# !python get-pip.py\n",
    "# !pip install --upgrade pip\n",
    "# !conda install nb_conda_kernels -y\n",
    "# !pip install ipykernel\n",
    "\n",
    "# virtual_environment = !conda info --envs | grep mmseg\n",
    "\n",
    "# if len(virtual_environment) != 0:\n",
    "#     print(\"virtual environment is already exist\")\n",
    "#     !conda remove -n mmseg --all --yes\n",
    "#     print(\"removed virtual environment\")\n",
    "    \n",
    "# !conda create -n mmseg python=3.7 -y\n",
    "# !conda info --envs\n",
    "\n",
    "# kernels = !jupyter kernelspec list\n",
    "\n",
    "# for line in list(kernels):\n",
    "#     if \"mmseg\" in line:\n",
    "#         print(f\"'mmseg' kernel is exists.\")\n",
    "#         !jupyter kernelspec remove mmseg -y\n",
    "#         print(\"removed kernel\")\n",
    "        \n",
    "# !python -m ipykernel install --user --name mmseg --display-name \"mmseg\"\n",
    "# !jupyter kernelspec list\n",
    "\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You must change kernel to mmseg!! [Python 3 (ipykernel) → mmseg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # mmseg_path = '/opt/ml/mmsegmentation'\n",
    "# mmseg_path = '/opt/ml/mmsegTest'\n",
    "\n",
    "# if os.path.isdir(mmseg_path):\n",
    "#     print(f\"Directory is already exist.({mmseg_path})\")\n",
    "#     !rm -r {mmseg_path}\n",
    "#     print(\"removed directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/open-mmlab/mmsegmentation.git {mmseg_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd {mmseg_path}\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pytorch=1.6.0 torchvision cudatoolkit=10.1 -c pytorch -y\n",
    "# !pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.6.0/index.html\n",
    "# !pip install mmcv\n",
    "# !pip install mmsegmentation\n",
    "# !pip install wandb\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T05:54:58.701660Z",
     "start_time": "2021-10-04T05:54:58.680659Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:06.631207Z",
     "start_time": "2021-10-04T06:16:06.620206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmseg_path = '/opt/ml/mmsegmentation'\n",
    "dataset_path  = '/opt/ml/segmentation/input/data'\n",
    "category_names = ['Backgroud', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        self.json_data = None\n",
    "        with open(data_dir, 'r') as f:\n",
    "            self.json_data = json.load(f)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        index = self.json_data['images'][index]['id']\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : len(idx['segmentation'][0]), reverse=False)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos, os.path.join(dataset_path, image_infos['file_name'])\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos, os.path.join(dataset_path, image_infos['file_name'])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T06:16:11.389706Z",
     "start_time": "2021-10-04T06:16:07.146708Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.47s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.58s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_json = 'train_5'\n",
    "val_json = 'val_5'\n",
    "test_json = 'test'\n",
    "\n",
    "train_path = dataset_path + f'/{train_json}.json'\n",
    "val_path = dataset_path + f'/{val_json}.json'\n",
    "test_path = dataset_path + f'/{test_json}.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([ToTensorV2()])\n",
    "val_transform = A.Compose([ToTensorV2()])\n",
    "test_transform = A.Compose([ToTensorV2()])\n",
    "\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory is already exist.(/opt/ml/mmsegmentation/data/images/test)\n",
      "Directory is already exist.(/opt/ml/mmsegmentation/data/annotations/test)\n"
     ]
    }
   ],
   "source": [
    "train_image_path = os.path.join(mmseg_path, f'data/images/{train_json}')\n",
    "val_image_path = os.path.join(mmseg_path, f'data/images/{val_json}')\n",
    "train_ann_path = os.path.join(mmseg_path, f'data/annotations/{train_json}')\n",
    "val_ann_path = os.path.join(mmseg_path, f'data/annotations/{val_json}')\n",
    "test_image_path = os.path.join(mmseg_path, f'data/images/{test_json}')\n",
    "test_ann_path = os.path.join(mmseg_path, f'data/annotations/{test_json}')\n",
    "\n",
    "dir_paths = [train_image_path, val_image_path, train_ann_path, val_ann_path, test_image_path, test_ann_path]\n",
    "\n",
    "def makedirs(path): \n",
    "    try: \n",
    "        os.makedirs(path) \n",
    "    except OSError: \n",
    "        print(f\"Directory is already exist.({path})\")\n",
    "        if not os.path.isdir(path): \n",
    "            raise\n",
    "\n",
    "for path in dir_paths:\n",
    "    makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask_image(mode, data_loader, image_path, ann_path=None):\n",
    "    print(f'Create {mode} data...')\n",
    "\n",
    "    if mode == 'train' or mode == 'val':\n",
    "        if ann_path==None:\n",
    "            print(f'ann_path is empty')\n",
    "            return\n",
    "        for images, masks, image_infos, imagepath in tqdm(data_loader):\n",
    "            image_file_path = os.path.join(image_path, f\"{image_infos[0]['id']:04}.jpg\")\n",
    "            anno_file_path = os.path.join(ann_path, f\"{image_infos[0]['id']:04}.png\")\n",
    "            \n",
    "            masks = masks[0].numpy()\n",
    "            shutil.copy2(imagepath[0], image_file_path)\n",
    "            cv2.imwrite(anno_file_path, masks)\n",
    "    elif mode == 'test':\n",
    "        for images, image_infos, imagepath in tqdm(data_loader):\n",
    "            image_file_path = os.path.join(image_path, f\"{image_infos[0]['id']:04}.jpg\")\n",
    "            shutil.copy2(imagepath[0], image_file_path)\n",
    "    else:\n",
    "        print(f\"mode = 'train' or 'val' or 'test'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2625 [00:00<00:45, 57.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2625/2625 [00:42<00:00, 62.23it/s] \n",
      "  1%|          | 6/646 [00:00<00:11, 57.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create val data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [00:09<00:00, 65.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_mask_image('train', train_loader, train_image_path, train_ann_path)\n",
    "generate_mask_image('val', val_loader, val_image_path, val_ann_path)\n",
    "# generate_mask_image('test', test_loader, test_image_path)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "d36e052b391be8c28b05838ade06426769a29575d5fe21a7bc69c7dec0c04c06"
  },
  "kernelspec": {
   "display_name": "mmseg",
   "language": "python",
   "name": "mmseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "394.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
